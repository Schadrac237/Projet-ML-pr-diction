# üß† Projet de Pr√©diction du Taux d'Attrition des Employ√©s

![Python](https://img.shields.io/badge/python-3.8%2B-blue) ![Jupyter Notebook](https://img.shields.io/badge/Jupyter-Notebook-orange) ![Licence: MIT](https://img.shields.io/badge/License-MIT-green.svg) ![Issues GitHub](https://img.shields.io/github/issues/Schadrac237/Projet-ML-pr-diction) ![√âtoiles GitHub](https://img.shields.io/github/stars/Schadrac237/Projet-ML-pr-diction)

## üìå Pr√©sentation du Projet

Ce projet a √©t√© r√©alis√© dans le cadre d‚Äôun travail de groupe acad√©mique portant sur l‚Äôapplication des techniques de machine learning pour pr√©dire le taux d‚Äôattrition des employ√©s au sein d‚Äôune entreprise. La pr√©diction de l‚Äôattrition est une probl√©matique cl√© en gestion des ressources humaines, car elle permet aux entreprises d‚Äôanticiper les d√©parts potentiels, d‚Äôam√©liorer les strat√©gies de r√©tention et d‚Äôoptimiser la planification des effectifs.

Le jeu de donn√©es fourni comprend diverses caract√©ristiques relatives aux employ√©s, qui ont √©t√© utilis√©es pour entra√Æner des mod√®les pr√©dictifs capables d‚Äôidentifier les collaborateurs susceptibles de quitter l‚Äôentreprise. L‚Äôobjectif principal √©tait de construire, d‚Äô√©valuer et de comparer plusieurs mod√®les de classification afin de s√©lectionner celui offrant la meilleure performance pour la pr√©diction.

## üéØ Objectifs

Les objectifs principaux du projet √©taient les suivants :

- R√©aliser un pr√©traitement complet des donn√©es incluant le nettoyage, la gestion des valeurs manquantes et l‚Äôencodage des variables pour pr√©parer le jeu de donn√©es √† l‚Äôapprentissage automatique.
- Entra√Æner plusieurs mod√®les de machine learning, notamment Random Forest, Decision Tree, SVM, R√©gression Logistique, KNN et Perceptron.
- √âvaluer la performance de chaque mod√®le en utilisant des m√©triques cl√©s telles que la pr√©cision, le rappel, le score F1 et l‚Äôaire sous la courbe (AUC).
- Analyser les r√©sultats afin d‚Äôidentifier le mod√®le le plus performant.
- Explorer des pistes d‚Äôam√©lioration pour les mod√®les moins performants via l‚Äôing√©nierie des caract√©ristiques ou l‚Äôoptimisation des hyperparam√®tres.
- Fournir des recommandations exploitables pour faciliter la prise de d√©cision RH √† partir des pr√©dictions g√©n√©r√©es.

## üß≠ M√©thodologie et Approche

Le d√©roulement du projet s‚Äôest articul√© autour des √©tapes suivantes :

1. **Nettoyage et Pr√©traitement des Donn√©es :**  
   Le jeu de donn√©es initial a √©t√© nettoy√© afin de traiter les valeurs manquantes et d‚Äô√©liminer les variables non pertinentes ou redondantes. Les variables cat√©gorielles ont √©t√© encod√©es par des m√©thodes adapt√©es telles que l‚Äôencodage one-hot pour assurer la compatibilit√© avec les algorithmes de machine learning.

2. **S√©paration du Jeu de Donn√©es :**  
   Les donn√©es pr√©par√©es ont √©t√© divis√©es en ensembles d‚Äôentra√Ænement et de test pour garantir une √©valuation impartiale des performances des mod√®les.

3. **D√©veloppement des Mod√®les :**  
   Plusieurs algorithmes de classification ont √©t√© impl√©ment√©s en Python dans un environnement Jupyter Notebook, en utilisant des biblioth√®ques reconnues comme pandas pour la manipulation des donn√©es, numpy pour les op√©rations num√©riques, matplotlib pour la visualisation et scikit-learn pour la construction et l‚Äô√©valuation des mod√®les.

4. **√âvaluation des Mod√®les :**  
   Chaque mod√®le a √©t√© √©valu√© √† l‚Äôaide de m√©triques essentielles telles que la pr√©cision, le rappel, le score F1 et l‚ÄôAUC, afin de mesurer leur capacit√© √† classer correctement les cas d‚Äôattrition.

5. **Analyse des Performances :**  
   Les m√©thodes d‚Äôensemble telles que Random Forest et Decision Tree ont montr√© une performance exceptionnelle avec des scores tr√®s √©lev√©s, tandis que des mod√®les plus simples comme le Perceptron ont affich√© des r√©sultats plus modestes.

6. **Contribution et Collaboration :**  
   Ce projet a √©t√© r√©alis√© en √©quipe. Mes contributions ont inclus l‚Äôentra√Ænement et l‚Äô√©valuation d‚Äôun mod√®le de machine learning, le nettoyage des donn√©es, ainsi que la gestion de la s√©paration des donn√©es en ensembles d‚Äôentra√Ænement et de test. Une collaboration r√©guli√®re a permis d‚Äôassurer la coh√©rence et d‚Äôoptimiser les r√©sultats.

## üõ†Ô∏è Technologies Utilis√©es

Le projet a utilis√© les outils et biblioth√®ques suivants :

- Python version 3.8 ou sup√©rieure pour le d√©veloppement et l‚Äôanalyse.
- Jupyter Notebook comme environnement interactif pour le d√©veloppement et la documentation.
- pandas pour la manipulation efficace des donn√©es.
- numpy pour les calculs num√©riques et la gestion des tableaux.
- matplotlib pour la visualisation des donn√©es et des r√©sultats.
- scikit-learn pour la construction, l‚Äôentra√Ænement et l‚Äô√©valuation des mod√®les de machine learning.

## üìä R√©sultats

| Mod√®le             | Pr√©cision | Rappel | Score F1 | AUC    |
|--------------------|-----------|--------|----------|--------|
| Perceptron         | 0.35      | 0.14   | 0.20     | N/A    |
| R√©gression Logistique | 0.67    | 0.26   | 0.38     | 0.77   |
| SVM                | 0.88      | 0.43   | 0.57     | 0.89   |
| KNN                | 0.51      | 0.42   | 0.46     | 0.92   |
| Decision Tree      | 0.93      | 0.94   | 0.94     | 0.96   |
| Random Forest      | 0.98      | 0.96   | 0.97     | 1.00   |

Les mod√®les Random Forest et Decision Tree ont d√©montr√© une excellente pr√©cision pr√©dictive, avec des scores AUC et F1 proches de la perfection, confirmant leur pertinence pour la t√¢che de pr√©diction d‚Äôattrition. Les mod√®les plus simples tels que le Perceptron ont des performances limit√©es, sugg√©rant la n√©cessit√© d‚Äôoptimisations suppl√©mentaires.

## ‚öôÔ∏è Utilisation du D√©p√¥t

Ce d√©p√¥t contient l‚Äôensemble du code source, incluant les √©tapes de pr√©traitement, les scripts d‚Äôentra√Ænement et d‚Äô√©valuation des mod√®les. Le jeu de donn√©es original est priv√© et n‚Äôest pas inclus pour des raisons de confidentialit√©.

